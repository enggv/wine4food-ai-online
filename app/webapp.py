from flask import Flask, render_template, request, url_for
import os
from PIL import Image
import torch
from torchvision import transforms
import timm
from pairings import wine_pairings
from huggingface_hub import hf_hub_download

app = Flask(__name__, static_folder='static')
UPLOAD_FOLDER = os.path.join(app.static_folder, 'uploads')
app.config['UPLOAD_FOLDER'] = UPLOAD_FOLDER
os.makedirs(UPLOAD_FOLDER, exist_ok=True)

ALLOWED_EXTENSIONS = {'png', 'jpg', 'jpeg', 'webp'}

def allowed_file(filename):
    return '.' in filename and filename.rsplit('.', 1)[1].lower() in ALLOWED_EXTENSIONS

def predict_image(image_path, confidence_threshold=0.5):
    transform = transforms.Compose([
        transforms.Resize((224, 224)),
        transforms.ToTensor(),
        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
    ])

    image = Image.open(image_path).convert("RGB")
    input_tensor = transform(image).unsqueeze(0)
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

    class_names = list(wine_pairings.keys())

    model = timm.create_model('efficientnet_b0', pretrained=False, num_classes=len(class_names))
    model_path = hf_hub_download(repo_id="enggv/food101-effnet-model", filename="food_model_101classes.pt")
    model.load_state_dict(torch.load(model_path, map_location=device))

    model.to(device)
    model.eval()

    with torch.no_grad():
        outputs = model(input_tensor.to(device))
        probs = torch.nn.functional.softmax(outputs, dim=1)
        max_prob, predicted_class = torch.max(probs, dim=1)
        confidence = max_prob.item()

    if confidence < confidence_threshold:
        return None

    return class_names[predicted_class.item()]

@app.route('/', methods=['GET', 'POST'])
def index():
    prediction = None
    wine = None
    image_url = None
    all_dishes = list(wine_pairings.keys())  # ðŸ”‘ Ð—Ð° Ð²Ð¸Ð·ÑƒÐ°Ð»Ð¸Ð·Ð°Ñ†Ð¸Ñ Ð² index.html

    if request.method == 'POST':
        file = request.files['image']
        if file:
            for existing_file in os.listdir(app.config['UPLOAD_FOLDER']):
                file_path = os.path.join(app.config['UPLOAD_FOLDER'], existing_file)
                try:
                    if os.path.isfile(file_path):
                        os.remove(file_path)
                except Exception as e:
                    print(f"âš ï¸ ÐÐµÑƒÑÐ¿ÐµÑ… Ð¿Ñ€Ð¸ Ð¸Ð·Ñ‚Ñ€Ð¸Ð²Ð°Ð½Ðµ Ð½Ð° {file_path}: {e}")

            if not allowed_file(file.filename):
                prediction = "Ð¤Ð°Ð¹Ð»ÑŠÑ‚ Ð½Ðµ Ðµ Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ðµ. ÐœÐ¾Ð»Ñ ÐºÐ°Ñ‡ÐµÑ‚Ðµ .jpg, .png Ð¸Ð»Ð¸ .webp Ñ„Ð°Ð¹Ð»."
                return render_template('index.html', prediction=prediction, all_dishes=all_dishes)

            filepath = os.path.join(app.config['UPLOAD_FOLDER'], file.filename)
            file.save(filepath)

            try:
                prediction = predict_image(filepath)
                if prediction is None:
                    prediction = "â— ÐÐµ ÑƒÑÐ¿ÑÑ…Ð¼Ðµ Ð´Ð° Ñ€Ð°Ð·Ð¿Ð¾Ð·Ð½Ð°ÐµÐ¼ Ñ…Ñ€Ð°Ð½Ð° Ð½Ð° Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸ÐµÑ‚Ð¾."
                    wine = None
                else:
                    wine = wine_pairings.get(prediction, "ÐÑÐ¼Ð° Ð½Ð°Ð»Ð¸Ñ‡Ð½Ð° Ð¿Ñ€ÐµÐ¿Ð¾Ñ€ÑŠÐºÐ°")
            except Exception as e:
                print(f"âŒ Ð“Ñ€ÐµÑˆÐºÐ° Ð¿Ñ€Ð¸ Ñ€Ð°Ð·Ð¿Ð¾Ð·Ð½Ð°Ð²Ð°Ð½Ðµ: {e}")
                prediction = "âš ï¸ Ð’ÑŠÐ·Ð½Ð¸ÐºÐ½Ð° Ð½ÐµÐ¾Ñ‡Ð°ÐºÐ²Ð°Ð½Ð° Ð³Ñ€ÐµÑˆÐºÐ° Ð¿Ñ€Ð¸ Ñ€Ð°Ð·Ð¿Ð¾Ð·Ð½Ð°Ð²Ð°Ð½Ðµ."
                wine = None

            image_url = url_for('static', filename='uploads/' + file.filename)
            print(f"ðŸ–¼ï¸ ÐŸÑŠÑ‚ ÐºÑŠÐ¼ Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸ÐµÑ‚Ð¾: {image_url}")

    return render_template('index.html', prediction=prediction, image_url=image_url, wine=wine, all_dishes=all_dishes)

if __name__ == '__main__':
    app.run(host='0.0.0.0', port=int(os.environ.get("PORT", 5000)))
